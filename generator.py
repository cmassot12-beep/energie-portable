# -*- coding: utf-8 -*-
"""
Zero-Cost AI Publisher
- Static site (Jekyll) hosted on GitHub Pages (free)
- Daily content generated by an open-source local model (TinyLlama) in GitHub Actions (free minutes on public repos)
- No WordPress, no paid API

This script:
- Picks a topic from topics.csv (or generates from seed)
- Uses an open-source model to generate an article
- Creates a Markdown post in _posts with front matter
- Injects affiliate links block (Amazon tag in env var AMZN_TAG, optional)
- Keeps a topics_done.txt to avoid duplicates
"""

import os, re, json, datetime, random, sys, pathlib
from pathlib import Path

from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

REPO_ROOT = Path(__file__).resolve().parent
DATA = REPO_ROOT / "data"
DATA.mkdir(exist_ok=True)

TOPICS = (REPO_ROOT / "topics.csv").read_text(encoding="utf-8").splitlines()
DONE_PATH = DATA / "topics_done.txt"
if not DONE_PATH.exists():
    DONE_PATH.write_text("", encoding="utf-8")

AMZN_TAG = os.getenv("AMZN_TAG", "yourtag-21")
AMZN_ASINS = os.getenv("AMZN_ASINS", "B09D8GKRWQ:Jackery Explorer 1000,B0B3DP4W6J:EcoFlow DELTA 2,B09TPTJ3T3:Bluetti EB70")

def parse_asins(raw: str):
    out = []
    for part in raw.split(","):
        if ":" in part:
            a, label = part.split(":",1)
            out.append((a.strip(), label.strip()))
    return out

def affiliate_block():
    items = [f"- [{label}](https://www.amazon.fr/dp/{asin}/?tag={AMZN_TAG})"
             for asin,label in parse_asins(AMZN_ASINS)]
    return "## Recommandations\n\n" + "\n".join(items) + "\n\n*Liens affiliés, rel=sponsored.*"

def choose_topic():
    done = set(DONE_PATH.read_text(encoding="utf-8").splitlines())
    candidates = [t for t in TOPICS if t.strip() and t not in done]
    if not candidates:
        # Reset if all used
        done = set()
        candidates = [t for t in TOPICS if t.strip()]
        DONE_PATH.write_text("", encoding="utf-8")
    topic = random.choice(candidates)
    return topic, done

def save_done(topic, done_set):
    done_set = set(done_set) | {topic}
    DONE_PATH.write_text("\n".join(sorted(done_set)), encoding="utf-8")

def load_model():
    model_id = os.getenv("MODEL_ID", "TinyLlama/TinyLlama-1.1B-Chat-v1.0")
    tok = AutoTokenizer.from_pretrained(model_id, use_fast=True)
    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float32)
    model.eval()
    return tok, model

SYS = ("Tu es un rédacteur SEO honnête. Tu écris en français de France, clair, structuré (H2/H3, listes), ton utile. "
       "Ne fabrique pas de chiffres non sourcés.")

PROMPT_TMPL = """<|system|>
{sys}
</s>
<|user|>
Rédige un article long (~1000-1300 mots) sur : "{topic}"
Contraintes:
- Structure claire avec H2/H3
- Paragraphes courts, listes à puces utiles
- Conseils concrets et sécurité
- Terminer par une FAQ (5 questions)
- N'insère pas toi-même de liens d'affiliation (je les ajoute).
Langue: Français (France)
</s>
<|assistant|>
"""

def generate_article(tok, model, topic):
    prompt = PROMPT_TMPL.format(sys=SYS, topic=topic)
    inputs = tok(prompt, return_tensors="pt")
    with torch.no_grad():
        out = model.generate(
            **inputs,
            max_new_tokens=1200,
            temperature=0.8,
            top_p=0.9,
            do_sample=True,
            eos_token_id=tok.eos_token_id,
        )
    text = tok.decode(out[0], skip_special_tokens=True)
    # Extract assistant part (after last </s> or split naive)
    parts = text.split("</s>")
    generated = parts[-1].strip()
    # Basic cleaning
    generated = re.sub(r"\n{3,}", "\n\n", generated).strip()
    return generated

def slugify(s: str):
    s = s.lower()
    s = re.sub(r"[^a-z0-9\\s-]", "", s)
    s = re.sub(r"\\s+", "-", s).strip("-")
    return s[:80]

def write_post(topic, body_md):
    today = datetime.date.today()
    slug = slugify(topic)
    fn = REPO_ROOT / "_posts" / f"{today:%Y-%m-%d}-{slug}.md"
    fn.parent.mkdir(exist_ok=True)
    fm = f"---\nlayout: post\ntitle: \"{topic}\"\n---\n\n"
    content = fm + body_md + "\n\n" + affiliate_block()
    fn.write_text(content, encoding="utf-8")
    return fn

def main():
    topic, done = choose_topic()
    tok, model = load_model()
    print(f"[+] Generating article about: {topic}")
    body = generate_article(tok, model, topic)
    path = write_post(topic, body)
    save_done(topic, done)
    print(f"[✓] Wrote: {path}")

if __name__ == "__main__":
    main()
